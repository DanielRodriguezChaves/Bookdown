# Marco conceptual {#marco}

## Análisis de correspondencias múltiples

Como se presenta en Pardo [@Pardo, pp. 125 - 163], el análisis de correspondencias múltiples es una herramienta estadística cuyo objetivo es analizar asociaciones entre categorías de las variables de interés, esto a través de métodos gráficos que permitan observar cuales categorías de una variable son las que más afectan a las diferentes categorías de las otras variables, además permite reducir la dimensión de la matriz de datos de tal manera que se pueda llegar a observar las relaciones de las categorías usando un gráfico bidimensional. Se puede entender como un análisis de correspondencias simples aplicado a una tabla disyuntiva completa o bien aplicado a la tabla de Burt correspondiente teniendo en cuenta que en este caso se pierde la información por individuo. El método, como ya se dijo, se puede entender como la generalización de un análisis de correspondencias simple al caso de más de dos variables categóricas de interés, pero también se puede entender como la realización de dos diferentes análisis de componentes principales, uno de ellos permite hacer los cálculos de una manera relativamente sencilla y el otro ayuda a llevar a cabo la interpretación de los ejes obtenidos, en general, esta interpretación se hace únicamente sobre las categorías de las variables y no sobre los individuos ya que los últimos son, en la mayoría de los casos, anónimos. Para seleccionar el número de ejes a retener se usan dos metodologías, la primera es elegir el número a través del histograma de valores propios de los ejes de acuerdo a la cantidad de valores propios que se puedan considerar diferentes, y si hay muchos valores propios similares se considera que pertenecen a ejes "parásitos", es decir a ejes que no brindan más información. La segunda metodología se conoce como el criterio de Benzecri, dentro de los ejes cuyo valor propio sea mayor al inverso del número de categorías dentro del análisis se recalcula las tasas de inercia y se selecciona el número de ejes a través del histograma de las tasas de inercia recalculadas de la misma manera que se hizo con el histograma de valores propios. El análisis de correspondencias múltiples permite, además, incluir la proyección de variables que no participaron en la construcción de los ejes, a estas variables se les conoce como suplementarias y sirve para describir las posibles relaciones que presentan esas categorías suplementarias con las categorías de las variables activas del análisis.

## Modelos multinomiales

Cuando en un problema de modelación estadística, la variable dependiente o de respuesta es de tipo categórico nominal una de las opciones para llevar a cabo el análisis es recurrir a modelos logit de categoría base adecuados a respuestas de tipo nominal [@Agresti, pp. 267]. Este modelo, también conocido como modelo multinomial, es un análisis conjunto de modelos logit binarios para cada par de categorías como se observa en la ecuación (1):

$$\log { \left( \frac { { \pi  }_{ j } }{ { \pi  }_{ J } }  \right)  } ={ \alpha  }_{ j }+{ \beta  }_{ j }x,\quad \quad \quad j=1,\cdots ,J-1 \quad \quad(1)$$

Donde $J$ es el número total de categórias, $x$ es una matriz cuyas columnas corresponden a las variables explicativas, ${ \alpha  }_{ j }$ y ${ \beta  }_{ j }$  son los parámetros a estimar en el modelo y  ${ \pi  }_{ j }(x)=P(Y=j|x)$ las probabilidades asociadas a cada una de las categorías de la variable respuesta $Y$ con $\sum _{ j=1 }^{ J }{ { \pi  }_{ j }(x) } =1$. Nótese que se puede hallar la asociación de cualquier par de categorías a través de la ecuación (2): 

$$\log { \left( \frac { { \pi  }_{ a } }{ { \pi  }_{ b } }  \right)  } =\log { \left( \frac { { \pi  }_{ a } }{ { \pi  }_{ J } }  \right)  } -\log { \left( \frac { { \pi  }_{ b } }{ { \pi  }_{ J } }  \right)  } \quad \quad (2)$$

Para llevar a cabo la comparación entre modelos y poder seleccionar el más adecuado, en términos de cuáles son las variables que lo van a conformar y de la parsimonia del modelo, se usa el AIC o criterio de información de Akaike, el cual evalúa al modelo de acuerdo a la cercanía entre los valores ajustados a través del modelo y los verdaderos valores penalizando por el número de parámetros [@Agresti, pp. 216] y permite comparar el ajuste de modelos que no están anidados. Cuando se usa el AIC el modelo que más se ajusta a los datos será aquel que tenga menor AIC y también se usa el BIC o criterio de información bayesiano, el cual es muy similar al AIC, pero además toma en cuenta el tamaño de la muestra [@Agresti, pp. 257]. El proceso que se lleva a cabo para la selección del modelo se conoce como backward o eliminación hacia atrás, y se conduce como en @Agresti[ pp. 214], es decir se parte del modelo más completo y se elimina un parámetro a la vez. Para llevar a cabo la estimación de las probabilidades de respuesta a través del modelo se aplica la fórmula (3):

$${ \hat { \pi  }  }_{ j }(x)=\frac { exp({ \hat { \alpha  }  }_{ j }+{ \hat { \beta ' }  }_{ j }x) }{ 1+\sum _{ h=1 }^{ J-1 }{ exp({ \hat { \alpha  }  }_{ h }+{ \hat { \beta ' }  }_{ h }x) }  } \quad \quad (3)$$

Y como se observa en la ecuación (4), los parámetros se pueden interpretar a través del logit de una probabilidad condicional:

$$\log { \left( \frac { { \pi  }_{ j } }{ { \pi  }_{ J } }  \right)  } =\log { \left( \frac { \left( \frac { { \pi  }_{ j } }{ { \pi  }_{ J }+{ \pi  }_{ j } }  \right)  }{ \left( \frac { { \pi  }_{ J } }{ { \pi  }_{ J }+{ \pi  }_{ j } }  \right)  }  \right)  } =\log { \left( \frac { \left( \frac { { \pi  }_{ j } }{ { \pi  }_{ J }+{ \pi  }_{ j } }  \right)  }{ 1-\left( \frac { { \pi  }_{ j } }{ { \pi  }_{ J }+{ \pi  }_{ j } }  \right)  }  \right)  } =logit\left( \frac { { \pi  }_{ j } }{ { \pi  }_{ J }+{ \pi  }_{ j } }  \right) \quad \quad (4)$$

## Modelos multinomiales logísticos multinivel 

Los modelos multinivel aparecen, principalmente, en aplicaciones de la estadística para hacer análisis con respecto a la educación [@Goldstein]. Surgen como una ampliación a los modelos generalizados ya existentes, para los cuales uno de sus supuestos básicos es la independencia de las observaciones, pero al observar que los individuos que se están analizando se encuentran agrupados (estudiantes dentro de salones, salones dentro de colegios, etc…) y que dentro de los grupos los individuos, en general, son similares pero entre grupos existen diferencias más claras, es decir, se viola el supuesto de independencia los modelos existentes ya no son válidos en este caso. En términos simples, el modelo multinivel hace una corrección al problema de independencia a través de la inclusión de variables aleatorias correspondientes a los múltiples niveles de anidación de nuestros datos y que permiten llevar cabo estimaciones correctas de los parámetros del modelo. Para nuestro caso el modelo de interés es de respuesta categórica nominal, de ahí que el modelo a usar resulte un modelo multinomial logístico multinivel [@Goldstein] de manera en que se especifica en la fórmula (5):

$$\log { \left( \frac { { { \pi  }_{ j } }^{ (s) } }{ { { \pi  }_{ J } }^{ (s) } }  \right)  } ={ \alpha  }_{ j }+{ \beta  }_{ j }{ x }^{ (s) }+{ { u }_{ j } }^{ (s) },\quad \quad \quad j=1,\cdots ,J-1\quad \quad (5)$$

Donde $J$ es el número total de categórias, x es una matriz cuyas columnas corresponden a las variables explicativas, ${ \alpha  }_{ j }$ y ${ \beta  }_{ j }$ son los parámetros a estimar en el modelo, $s$ es el nivel de agrupación de las observaciones y  ${ { \pi  }_{ j } }^{ (s) }({ x }^{ (s) })=P(Y=j|{ x }^{ (s) },s)$ las probabilidades asociadas a cada una de las categorías de la variable respuesta Y en cada uno de los niveles ($S$),   $\sum _{ j=1 }^{ J }{ \sum _{ s=1 }^{ S }{ { { \pi  }_{ j } }^{ (s) }(x) }  } =1$ y el ${ { u }_{ j } }^{ (s) }$ es un error aleatorio asociado a cada nivel.
Se tienen como opciones la cuasi verosimilitud, la máxima verosimilitud o los procedimientos MCMC para la estimación de los parámetros. Pero como se presenta en [@HadfieldBook]: 

_“En el contexto de los modelos lineales generalizados mixtos (GLMM), aquí está lo que yo observo como los pros y los contras de usar máxima verosimilitud (restringida - REML) versus los métodos bayesianos de Cadenas de Markov de Monte Carlo (MCMC). REML son rápidos y fáciles de usar, mientras los métodos MCMC pueden ser lentos y más retadores técnicamente. En particular, el reto es la especificación de una apiori sensible, el cual no es una dificultad con REML. Sin embargo, los resultados analíticos para GLMM no Gaussianos en general no están disponibles y REML se basa en procedimientos que usan métodos de máxima verosimilitud aproximada que pueden no funcionar bien. MCMC también es una aproximación, pero la exactitud de la aproximación incrementa en la misma medida que aumenta la longitud del análisis, siendo exactos al límite. Adicionalmente REML usa teoría de grandes muestras para derivar las aproximaciones de los intervalos de confianza los cuales pueden ser muy pobres especialmente para las varianzas. Nuevamente, las medidas de confianza de MCMC son exactas, excepto por el error de Monte Carlo, y proveen de una manera fácil e intuitiva de obtener medidas de confianza derivadas de las estadísticas como las razones de varianza, correlaciones y predicciones.”_

Luego para tamaños de muestra grandes y siempre que los métodos computacionales estén disponibles se puede acudir a métodos de estimación REML, en los demás casos la solución será acudir a métodos de estimación MCMC. Para más detalles sobre la estimación de parámetros de los modelos multinivel desde la perspectiva frecuentista de los modelos multinivel véase (Goldstein, 2010) y para la estimación de los parámetros desde la perspectiva bayesiana véase [@Goldstein] y/o [@HadfieldBook].
Para validar los supuestos y ajuste de los modelos multinivel existen dos caminos a seguir y dependen de la manera en que decidamos hacer la estimación de los parámetros de nuestro modelo. En la primera manera, es decir, la frecuentista o REML los supuestos son: en primera medida que los datos provengan de la distribución de probabilidades teorizada por el modelo, pero a diferencia de los modelos lineales generalizados usuales, los modelos multinivel no requieren la independencia de los errores. En la segunda manera, es decir, la bayesiana o MCMC los supuestos son: que los datos provengan de la distribución de probabilidades teorizada por el modelo, que la distribución a priori (que puede, o no, ser informativa) conjugue con la función de máxima verosimilitud de los datos, además se debe verificar que las cadenas de Márkov converjan para la estimación de los parámetros. Al llevar a cabo las verificaciones anteriormente descritas y apropiadas al método usado para la estimación entonces se garantiza que nuestro modelo ha sido validado y que el mismo se ha ajustado a nuestros datos.

## Software estadístico R:

R es un leguaje y ambiente de computación estadístico de código libre (GNU project) construido para dar sentido y valor agregado a los datos. R provee de una muy amplia variedad de herramientas estadísticas la cual es alimentada por su activa y creciente comunidad de colaboradores y usuarios. RStudio es una IDE (entorno de desarrollo integrado) para R, la comunidad de desarrolladores de RStudio inspirados por las innovaciones de los usuarios de R en las ciencias, educación e industria desarrollaron gran cantidad de herramientas, la mayoría libres, que permite dar gran valor añadido a los datos (dashboards, htmlwidgets, libros, etc…) y para que los equipos de trabajo puedan promover y compartir el trabajo posicionando a R como el lenguaje estadístico, de inteligencia de negocios y de ciencia de datos más poderoso, innovador y de mayor crecimiento en el mundo. Entre la gran variedad de librerías que posee R describiremos a continuación aquellas que fueron utilizadas en el desarrollo del proyecto. **Referencias:** [@r1], [@wikiR], [@wikiRStudio], [@rstudio1], [@rstudio2].

###	Librería tidyverse:

Es una colección de paquetes de R diseñados para ciencia de datos. Todos los paquetes comparten una filosofía de diseño subyacente, gramática y estructuras de datos. Contiene ggplot2 la cual es una librería poderosa para hacer gráficos estáticos por capas, dplyr la cual sirve para la manipulación de datos, tidyr la cual ayuda a depurar las bases de datos, readr para la lectura de datos rectangulares, readxl para la lectura de archivos .xls y .xlsx, purrr la cual permite hacer programación funcional, tibble la cual es una manera moderna de pensar las estructuras de datos, stringr la cual se encarga de que el trabajo con caracteres (strings) sea lo más sencillo posible, forcats la cual permite solucionar problemas frecuentes con la manipulación de factores, entre otros muchos paquetes. **Referencias:** [@tidyverse]

###	Librería Factoclass:

Como lo describe dos de sus autores Campo Elías Pardo (profesor asociado del Departamento de Estadística de la Universidad Nacional de Colombia) y Pedro César del Campo (Estadístico de la Universidad Nacional de Colombia) en [@Pardo2007], el paquete se implementó con la finalidad de llevar a cabo exploración multivariada de datos de acuerdo con las estrategias descritas en [@Lebart] . **Referencias:** [@Factoclass]

###	Librería lme4:

Es una librería construida para el ajuste de modelos lineales de efectos mixtos y modelos lineales generalizados de efectos mixtos desde un enfoque de máxima verosimilitud restringida. **Referencias:** [@lme4], [@Bates]

###	Librería MCMCglmm: 

Es una librería de R la cual tiene como objetivo ajustar modelos lineales generalizados mixtos con un enfoque bayesiano a través del uso de Cadenas de Markov Monte Carlo (MCMC). **Referencias:** [@MCMCglmm], [@HadfieldBook], [@HadfieldCourseNotes].

